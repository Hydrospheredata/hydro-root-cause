{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:19.579822Z",
     "start_time": "2019-04-10T09:24:18.379873Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:20.611467Z",
     "start_time": "2019-04-10T09:24:19.581937Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T13:15:46.853274Z",
     "start_time": "2019-04-08T13:15:46.850465Z"
    }
   },
   "source": [
    "Get adult data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:21.217260Z",
     "start_time": "2019-04-10T09:24:20.612864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helepr function to process the data\n",
    "def map_array_values(series, value_map):\n",
    "    if series.dtype == 'object':\n",
    "        ret = series.str.strip().copy()\n",
    "    else:\n",
    "        ret = series.copy()\n",
    "    for src, target in value_map.items():\n",
    "        ret[ret == src] = target\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Readble feature names\n",
    "feature_names = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "                 \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "                 \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "                 \"Capital Loss\", \"Hours per week\", \"Country\", 'Income']\n",
    "features_to_use = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "categorical_features = [1, 3, 5, 6, 7, 8, 9, 10, 11, 13]\n",
    "education_map = {\n",
    "    '10th': 'Dropout', '11th': 'Dropout', '12th': 'Dropout', '1st-4th':\n",
    "        'Dropout', '5th-6th': 'Dropout', '7th-8th': 'Dropout', '9th':\n",
    "        'Dropout', 'Preschool': 'Dropout', 'HS-grad': 'High School grad',\n",
    "    'Some-college': 'High School grad', 'Masters': 'Masters',\n",
    "    'Prof-school': 'Prof-School', 'Assoc-acdm': 'Associates',\n",
    "    'Assoc-voc': 'Associates',\n",
    "}\n",
    "occupation_map = {\n",
    "    \"Adm-clerical\": \"Admin\", \"Armed-Forces\": \"Military\",\n",
    "    \"Craft-repair\": \"Blue-Collar\", \"Exec-managerial\": \"White-Collar\",\n",
    "    \"Farming-fishing\": \"Blue-Collar\", \"Handlers-cleaners\":\n",
    "        \"Blue-Collar\", \"Machine-op-inspct\": \"Blue-Collar\", \"Other-service\":\n",
    "        \"Service\", \"Priv-house-serv\": \"Service\", \"Prof-specialty\":\n",
    "        \"Professional\", \"Protective-serv\": \"Other\", \"Sales\":\n",
    "        \"Sales\", \"Tech-support\": \"Other\", \"Transport-moving\":\n",
    "        \"Blue-Collar\",\n",
    "}\n",
    "country_map = {\n",
    "    'Cambodia': 'SE-Asia', 'Canada': 'British-Commonwealth', 'China':\n",
    "        'China', 'Columbia': 'South-America', 'Cuba': 'Other',\n",
    "    'Dominican-Republic': 'Latin-America', 'Ecuador': 'South-America',\n",
    "    'El-Salvador': 'South-America', 'England': 'British-Commonwealth',\n",
    "    'France': 'Euro_1', 'Germany': 'Euro_1', 'Greece': 'Euro_2',\n",
    "    'Guatemala': 'Latin-America', 'Haiti': 'Latin-America',\n",
    "    'Holand-Netherlands': 'Euro_1', 'Honduras': 'Latin-America',\n",
    "    'Hong': 'China', 'Hungary': 'Euro_2', 'India':\n",
    "        'British-Commonwealth', 'Iran': 'Other', 'Ireland':\n",
    "        'British-Commonwealth', 'Italy': 'Euro_1', 'Jamaica':\n",
    "        'Latin-America', 'Japan': 'Other', 'Laos': 'SE-Asia', 'Mexico':\n",
    "        'Latin-America', 'Nicaragua': 'Latin-America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'Latin-America', 'Peru':\n",
    "        'South-America', 'Philippines': 'SE-Asia', 'Poland': 'Euro_2',\n",
    "    'Portugal': 'Euro_2', 'Puerto-Rico': 'Latin-America', 'Scotland':\n",
    "        'British-Commonwealth', 'South': 'Euro_2', 'Taiwan': 'China',\n",
    "    'Thailand': 'SE-Asia', 'Trinadad&Tobago': 'Latin-America',\n",
    "    'United-States': 'United-States', 'Vietnam': 'SE-Asia'\n",
    "}\n",
    "married_map = {\n",
    "    'Never-married': 'Never-Married', 'Married-AF-spouse': 'Married',\n",
    "    'Married-civ-spouse': 'Married', 'Married-spouse-absent':\n",
    "        'Separated', 'Separated': 'Separated', 'Divorced':\n",
    "        'Separated', 'Widowed': 'Widowed'\n",
    "}\n",
    "\n",
    "\n",
    "# Transform Continiouse Cap Gains into the discrete variable\n",
    "def cap_gains_fn(x):\n",
    "    x = x.astype(float)\n",
    "    d = np.digitize(x, [0, np.median(x[x > 0]), float('inf')], right=True)\n",
    "    new_series = pd.Series([\"None\"] * len(d))\n",
    "    new_series[d == 0] = 'None'\n",
    "    new_series[d == 1] = 'Low'\n",
    "    new_series[d == 2] = 'High'\n",
    "    return new_series\n",
    "\n",
    "# Specify transofrmations for each column\n",
    "transformations = {\n",
    "    'Education': lambda x: map_array_values(x, education_map),\n",
    "    'Marital Status': lambda x: map_array_values(x, married_map),\n",
    "    'Occupation': lambda x: map_array_values(x, occupation_map),\n",
    "    'Capital Gain': cap_gains_fn,\n",
    "    'Capital Loss': cap_gains_fn,\n",
    "    'Country': lambda x: map_array_values(x, country_map),\n",
    "}\n",
    "\n",
    "# Load df\n",
    "df = pd.read_csv(\"../anchor2/anchor2/examples/data/adult/adult.data\", header=None)\n",
    "df.columns = feature_names\n",
    "target_labels = pd.Series(df.iloc[:, -1], index=df.index)\n",
    "df = df.iloc[:, features_to_use]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Transform features\n",
    "for feature, fun in transformations.items():\n",
    "    df[feature] = fun(df[feature])\n",
    "\n",
    "# Store dictionary with {Category id -> category classes}\n",
    "categorical_features_idx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 11]\n",
    "categorical_names = {}  # Dictionary with (Category id -> category classes)\n",
    "for f_idx in categorical_features_idx:\n",
    "    le = LabelEncoder()\n",
    "    df.iloc[:, f_idx] = le.fit_transform(df.iloc[:, f_idx])\n",
    "    categorical_names[f_idx] = le.classes_\n",
    "\n",
    "# Encode target label\n",
    "le = LabelEncoder()\n",
    "target_labels = le.fit_transform(target_labels)\n",
    "class_names = list(le.classes_)\n",
    "\n",
    "# Split the dataset into train\\val\\test\n",
    "train_X, rest_X, train_y, rest_y = sklearn.model_selection.train_test_split(df, target_labels, stratify=target_labels,\n",
    "                                                                            test_size=0.5, random_state=42)\n",
    "val_X, test_X, val_y, test_y = sklearn.model_selection.train_test_split(rest_X, rest_y, stratify=rest_y,\n",
    "                                                                        test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:21.224013Z",
     "start_time": "2019-04-10T09:24:21.219037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               33\n",
      "Workclass          4\n",
      "Education          0\n",
      "Marital Status     0\n",
      "Occupation         2\n",
      "Relationship       0\n",
      "Race               4\n",
      "Sex                1\n",
      "Capital Gain       2\n",
      "Capital Loss       2\n",
      "Hours per week    40\n",
      "Country            9\n",
      "Name: 14035, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(range(test_X.shape[0]))\n",
    "x = test_X.iloc[idx]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T13:28:57.387064Z",
     "start_time": "2019-04-08T13:28:57.384800Z"
    }
   },
   "source": [
    "Specify the hydrosphere inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:22.132154Z",
     "start_time": "2019-04-10T09:24:22.130019Z"
    }
   },
   "outputs": [],
   "source": [
    "service_link = \"https://dev.k8s.hydrosphere.io/gateway/application/adult-salary-app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T11:37:30.180106Z",
     "start_time": "2019-04-10T11:37:30.177009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to store sample in a json with signature specified by Ilnur\n",
    "def make_signatured_json(sample):\n",
    "    output_json = {}\n",
    "    names = sample.index\n",
    "    values = sample.values\n",
    "    for n, v in zip(names, values):\n",
    "        output_json[n] = [[int(v)]]\n",
    "    return output_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get response for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T11:37:31.453583Z",
     "start_time": "2019-04-10T11:37:30.837107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label is  <=50K\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=service_link, json=make_signatured_json(test_X.iloc[idx]))\n",
    "prediction = np.array(response.json()[\"Prediction\"])\n",
    "print(f\"Predicted label is {class_names[prediction[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the link to Anchor explanation service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:24:32.746555Z",
     "start_time": "2019-04-10T09:24:32.744253Z"
    }
   },
   "outputs": [],
   "source": [
    "anchor_link = \"http://0.0.0.0:5000/anchor2_adult\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchor service is already configured for this application, we just need to pass explained service and link to the reqstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate reqstore with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:33:07.597636Z",
     "start_time": "2019-04-10T09:54:34.832547Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148a448063174d799d820a5588effe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8141), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in tqdm(range(test_X.shape[0])):\n",
    "    response = requests.post(url=service_link, json=make_signatured_json(test_X.iloc[idx]))\n",
    "#     time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request for explanation with our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:03:47.581656Z",
     "start_time": "2019-04-10T13:02:16.902104Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.post(url=anchor_link, json={\"sample\": [x.tolist()]})  # Send image in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:03:47.587747Z",
     "start_time": "2019-04-10T13:03:47.583374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage of this explanation is  0.081\n",
      "Precision of this explanation is  0.982\n"
     ]
    }
   ],
   "source": [
    "print(\"Coverage of this explanation is \", response.json()['coverage'])\n",
    "print(\"Precision of this explanation is \", response.json()['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T13:03:47.593758Z",
     "start_time": "2019-04-10T13:03:47.589611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Capital Gain == None',\n",
       " 'Sex ==  Male',\n",
       " 'Occupation == Blue-Collar',\n",
       " 'Capital Loss == None',\n",
       " 'Hours per week < 84.0',\n",
       " 'Age < 63.0']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['explanation'].split(\" AND \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
