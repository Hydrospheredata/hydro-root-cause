{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T13:02:36.547009Z",
     "start_time": "2019-04-17T13:02:36.538257Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T13:02:36.777270Z",
     "start_time": "2019-04-17T13:02:36.773022Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T13:15:46.853274Z",
     "start_time": "2019-04-08T13:15:46.850465Z"
    }
   },
   "source": [
    "Get adult data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:59:54.884115Z",
     "start_time": "2019-04-15T11:59:54.314207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helepr function to process the data\n",
    "def map_array_values(series, value_map):\n",
    "    if series.dtype == 'object':\n",
    "        ret = series.str.strip().copy()\n",
    "    else:\n",
    "        ret = series.copy()\n",
    "    for src, target in value_map.items():\n",
    "        ret[ret == src] = target\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Readble feature names\n",
    "feature_names = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "                 \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "                 \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "                 \"Capital Loss\", \"Hours per week\", \"Country\", 'Income']\n",
    "features_to_use = [0, 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "categorical_features = [1, 3, 5, 6, 7, 8, 9, 10, 11, 13]\n",
    "education_map = {\n",
    "    '10th': 'Dropout', '11th': 'Dropout', '12th': 'Dropout', '1st-4th':\n",
    "        'Dropout', '5th-6th': 'Dropout', '7th-8th': 'Dropout', '9th':\n",
    "        'Dropout', 'Preschool': 'Dropout', 'HS-grad': 'High School grad',\n",
    "    'Some-college': 'High School grad', 'Masters': 'Masters',\n",
    "    'Prof-school': 'Prof-School', 'Assoc-acdm': 'Associates',\n",
    "    'Assoc-voc': 'Associates',\n",
    "}\n",
    "occupation_map = {\n",
    "    \"Adm-clerical\": \"Admin\", \"Armed-Forces\": \"Military\",\n",
    "    \"Craft-repair\": \"Blue-Collar\", \"Exec-managerial\": \"White-Collar\",\n",
    "    \"Farming-fishing\": \"Blue-Collar\", \"Handlers-cleaners\":\n",
    "        \"Blue-Collar\", \"Machine-op-inspct\": \"Blue-Collar\", \"Other-service\":\n",
    "        \"Service\", \"Priv-house-serv\": \"Service\", \"Prof-specialty\":\n",
    "        \"Professional\", \"Protective-serv\": \"Other\", \"Sales\":\n",
    "        \"Sales\", \"Tech-support\": \"Other\", \"Transport-moving\":\n",
    "        \"Blue-Collar\",\n",
    "}\n",
    "country_map = {\n",
    "    'Cambodia': 'SE-Asia', 'Canada': 'British-Commonwealth', 'China':\n",
    "        'China', 'Columbia': 'South-America', 'Cuba': 'Other',\n",
    "    'Dominican-Republic': 'Latin-America', 'Ecuador': 'South-America',\n",
    "    'El-Salvador': 'South-America', 'England': 'British-Commonwealth',\n",
    "    'France': 'Euro_1', 'Germany': 'Euro_1', 'Greece': 'Euro_2',\n",
    "    'Guatemala': 'Latin-America', 'Haiti': 'Latin-America',\n",
    "    'Holand-Netherlands': 'Euro_1', 'Honduras': 'Latin-America',\n",
    "    'Hong': 'China', 'Hungary': 'Euro_2', 'India':\n",
    "        'British-Commonwealth', 'Iran': 'Other', 'Ireland':\n",
    "        'British-Commonwealth', 'Italy': 'Euro_1', 'Jamaica':\n",
    "        'Latin-America', 'Japan': 'Other', 'Laos': 'SE-Asia', 'Mexico':\n",
    "        'Latin-America', 'Nicaragua': 'Latin-America',\n",
    "    'Outlying-US(Guam-USVI-etc)': 'Latin-America', 'Peru':\n",
    "        'South-America', 'Philippines': 'SE-Asia', 'Poland': 'Euro_2',\n",
    "    'Portugal': 'Euro_2', 'Puerto-Rico': 'Latin-America', 'Scotland':\n",
    "        'British-Commonwealth', 'South': 'Euro_2', 'Taiwan': 'China',\n",
    "    'Thailand': 'SE-Asia', 'Trinadad&Tobago': 'Latin-America',\n",
    "    'United-States': 'United-States', 'Vietnam': 'SE-Asia'\n",
    "}\n",
    "married_map = {\n",
    "    'Never-married': 'Never-Married', 'Married-AF-spouse': 'Married',\n",
    "    'Married-civ-spouse': 'Married', 'Married-spouse-absent':\n",
    "        'Separated', 'Separated': 'Separated', 'Divorced':\n",
    "        'Separated', 'Widowed': 'Widowed'\n",
    "}\n",
    "\n",
    "\n",
    "# Transform Continiouse Cap Gains into the discrete variable\n",
    "def cap_gains_fn(x):\n",
    "    x = x.astype(float)\n",
    "    d = np.digitize(x, [0, np.median(x[x > 0]), float('inf')], right=True)\n",
    "    new_series = pd.Series([\"None\"] * len(d))\n",
    "    new_series[d == 0] = 'None'\n",
    "    new_series[d == 1] = 'Low'\n",
    "    new_series[d == 2] = 'High'\n",
    "    return new_series\n",
    "\n",
    "# Specify transofrmations for each column\n",
    "transformations = {\n",
    "    'Education': lambda x: map_array_values(x, education_map),\n",
    "    'Marital Status': lambda x: map_array_values(x, married_map),\n",
    "    'Occupation': lambda x: map_array_values(x, occupation_map),\n",
    "    'Capital Gain': cap_gains_fn,\n",
    "    'Capital Loss': cap_gains_fn,\n",
    "    'Country': lambda x: map_array_values(x, country_map),\n",
    "}\n",
    "\n",
    "# Load df\n",
    "df = pd.read_csv(\"../anchor2/anchor2/examples/data/adult/adult.data\", header=None)\n",
    "df.columns = feature_names\n",
    "target_labels = pd.Series(df.iloc[:, -1], index=df.index)\n",
    "df = df.iloc[:, features_to_use]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Transform features\n",
    "for feature, fun in transformations.items():\n",
    "    df[feature] = fun(df[feature])\n",
    "\n",
    "# Store dictionary with {Category id -> category classes}\n",
    "categorical_features_idx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 11]\n",
    "categorical_names = {}  # Dictionary with (Category id -> category classes)\n",
    "for f_idx in categorical_features_idx:\n",
    "    le = LabelEncoder()\n",
    "    df.iloc[:, f_idx] = le.fit_transform(df.iloc[:, f_idx])\n",
    "    categorical_names[f_idx] = le.classes_\n",
    "\n",
    "# Encode target label\n",
    "le = LabelEncoder()\n",
    "target_labels = le.fit_transform(target_labels)\n",
    "class_names = list(le.classes_)\n",
    "\n",
    "# Split the dataset into train\\val\\test\n",
    "train_X, rest_X, train_y, rest_y = sklearn.model_selection.train_test_split(df, target_labels, stratify=target_labels,\n",
    "                                                                            test_size=0.5, random_state=42)\n",
    "val_X, test_X, val_y, test_y = sklearn.model_selection.train_test_split(rest_X, rest_y, stratify=rest_y,\n",
    "                                                                        test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:59:54.891729Z",
     "start_time": "2019-04-15T11:59:54.885915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               36\n",
      "Workclass          4\n",
      "Education          4\n",
      "Marital Status     0\n",
      "Occupation         7\n",
      "Relationship       0\n",
      "Race               4\n",
      "Sex                1\n",
      "Capital Gain       2\n",
      "Capital Loss       2\n",
      "Hours per week    50\n",
      "Country            9\n",
      "Name: 14971, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(range(test_X.shape[0]))\n",
    "x = test_X.iloc[idx]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-08T13:28:57.387064Z",
     "start_time": "2019-04-08T13:28:57.384800Z"
    }
   },
   "source": [
    "Specify the hydrosphere inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:59:55.883489Z",
     "start_time": "2019-04-15T11:59:55.881012Z"
    }
   },
   "outputs": [],
   "source": [
    "service_link = \"https://dev.k8s.hydrosphere.io/gateway/application/adult-salary-app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:59:56.973284Z",
     "start_time": "2019-04-15T11:59:56.968431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to store sample in a json with signature specified by Ilnur\n",
    "def make_signatured_json(sample):\n",
    "    output_json = {}\n",
    "    if type(sample) == pd.Series:\n",
    "        feature_names = sample.index\n",
    "        values = sample\n",
    "    else:\n",
    "        feature_names = [\n",
    "            \"Age\",\n",
    "            \"Workclass\",\n",
    "            \"Education\",\n",
    "            \"Marital Status\",\n",
    "            \"Occupation\",\n",
    "            \"Relationship\",\n",
    "            \"Race\",\n",
    "            \"Sex\",\n",
    "            \"Capital Gain\",\n",
    "            \"Capital Loss\",\n",
    "            \"Hours per week\",\n",
    "            \"Country\"]\n",
    "        values = sample\n",
    "        \n",
    "    for feature_idx, fname in enumerate(feature_names):\n",
    "        output_json[fname] = [int(v) for v in values.loc[:, fname]]\n",
    "    return output_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get response for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:49:21.500316Z",
     "start_time": "2019-04-12T12:49:20.978429Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label is  <=50K\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=service_link, json=make_signatured_json(test_X.iloc[idx]))\n",
    "prediction = np.array(response.json()[\"Prediction\"])\n",
    "print(f\"Predicted label is {class_names[prediction[0][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:00:01.523855Z",
     "start_time": "2019-04-15T11:59:59.452907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label is  <=50K\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=service_link, json=make_signatured_json(test_X.iloc[idx:idx+500]))\n",
    "prediction = np.array(response.json()[\"Prediction\"])\n",
    "print(f\"Predicted label is {class_names[prediction[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the link to Anchor explanation service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:00:06.307726Z",
     "start_time": "2019-04-15T12:00:06.305393Z"
    }
   },
   "outputs": [],
   "source": [
    "anchor_link = \"http://0.0.0.0:5000/anchor2_adult\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchor service is already configured for this application, we just need to pass explained service and link to the reqstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate reqstore with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T10:33:07.597636Z",
     "start_time": "2019-04-10T09:54:34.832547Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148a448063174d799d820a5588effe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8141), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in tqdm(range(test_X.shape[0])):\n",
    "    response = requests.post(url=service_link, json=make_signatured_json(test_X.iloc[idx]))\n",
    "#     time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T13:48:06.970371Z",
     "start_time": "2019-04-17T13:48:00.924663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5a35e2ed624f15b938b187a84a0681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. 200.. "
     ]
    }
   ],
   "source": [
    "service_link = \"https://dev.k8s.hydrosphere.io/gateway/application/adult-salary-app\"\n",
    "for idx in tqdm(range(test_X.shape[0]//500 - 1)):\n",
    "    sample = test_X.iloc[idx*500 :(idx +1)*500]    \n",
    "    response = requests.post(url=service_link, json=make_signatured_json(sample))\n",
    "    print(response.status_code, end=\".. \")\n",
    "#     time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request for explanation with our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T12:00:22.772542Z",
     "start_time": "2019-04-15T12:00:22.471251Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.post(url=anchor_link, json={\"sample\": [x.tolist()]})  # Send image in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T09:07:04.230333Z",
     "start_time": "2019-04-16T09:07:04.227827Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:45:17.951884Z",
     "start_time": "2019-04-12T13:45:17.948544Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Coverage of this explanation is \", response.json()['coverage'])\n",
    "print(\"Precision of this explanation is \", response.json()['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:45:17.958116Z",
     "start_time": "2019-04-12T13:45:17.954667Z"
    }
   },
   "outputs": [],
   "source": [
    "response.json()['explanation'].split(\" AND \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST REQSTORE - SOMEBODY STOLE MY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:20:19.823027Z",
     "start_time": "2019-04-16T10:20:19.304744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'54'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "application_name = \"adult-salary-app\"\n",
    "service_link = \"https://dev.k8s.hydrosphere.io/api/v2/application/\"\n",
    "reqstore_url = \"https://dev.k8s.hydrosphere.io/reqstore/\"\n",
    "\n",
    "r = requests.get(service_link + application_name)\n",
    "application_id = str(r.json()['executionGraph']['stages'][0]['modelVariants'][0]['modelVersion'][\"id\"])\n",
    "application_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:20:21.314837Z",
     "start_time": "2019-04-16T10:20:20.410719Z"
    }
   },
   "outputs": [],
   "source": [
    "b_data = APIHelper.download(reqstore_url, application_id)\n",
    "records = BinaryHelper.decode_records(b_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:34:36.221542Z",
     "start_time": "2019-04-16T10:34:36.217804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entries[-4].request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:24:54.663636Z",
     "start_time": "2019-04-16T10:24:54.658065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# all_entries = reduce(list.__add__, map(lambda r: r.entries, records))\n",
    "reqstore_requests  = []\n",
    "for entry in all_entries:\n",
    "    try:\n",
    "        r = entry.request\n",
    "        reqstore_requests.append(r)\n",
    "    except:\n",
    "        print(-1)\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:28:11.474887Z",
     "start_time": "2019-04-16T10:28:11.470935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqstore_requests[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:27:46.752424Z",
     "start_time": "2019-04-16T10:27:46.748737Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Fix processing of requests which has resulted in error\n",
    "# Helper functions to translate requests into pd.Series\n",
    "def request_to_df(r):\n",
    "    columns = []\n",
    "    values = []\n",
    "    for key, value in r.inputs.items():\n",
    "        columns.append(key)\n",
    "        if len(value.int64_val) == 0:\n",
    "            pass\n",
    "#             values.append(np.NAN)  # FIXME why this field is missing?\n",
    "        else:\n",
    "            values.append(value.int64_val)\n",
    "#     print(np.array(values).T)\n",
    "    columns = list(filter(lambda x: x!='', columns))\n",
    "    print(columns)\n",
    "\n",
    "    return pd.DataFrame(columns=columns, data=np.array(values).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:27:46.998799Z",
     "start_time": "2019-04-16T10:27:46.977706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status']\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty data passed with indices specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4856\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[0;32m-> 4857\u001b[0;31m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[1;32m   4858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-d8842e104944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_to_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqstore_requests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-8235884d2ad0>\u001b[0m in \u001b[0;36mrequest_to_df\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 379\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4864\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4865\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4866\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   4839\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4840\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4841\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4842\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m   4843\u001b[0m         passed, implied))\n",
      "\u001b[0;31mValueError\u001b[0m: Empty data passed with indices specified."
     ]
    }
   ],
   "source": [
    "x = list(map(request_to_df, reqstore_requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:21:07.804602Z",
     "start_time": "2019-04-16T10:21:07.802117Z"
    }
   },
   "outputs": [],
   "source": [
    "# x = pd.concat(x, sort=False)\n",
    "\n",
    "# # Remove [1, 1, 1, ...] which results from UI test model calls\n",
    "# x = x.loc[~np.all(x == np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), axis=1)]\n",
    "# x.dropna(inplace=True)\n",
    "# x.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T10:20:58.217095Z",
     "start_time": "2019-04-16T10:20:58.202790Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from itertools import chain\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import hydro_serving_grpc as hs\n",
    "import requests\n",
    "\n",
    "\n",
    "class APIHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def _urljoin(address, name, path):\n",
    "        return urljoin(address, \"/\".join([name, path]))\n",
    "\n",
    "    @staticmethod\n",
    "    def download(address, name):\n",
    "        url = APIHelper._urljoin(address, name, \"get\")\n",
    "        r = requests.get(url, stream=True)\n",
    "        return r.content\n",
    "\n",
    "\n",
    "class BinaryHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def read_int(binary: BytesIO):\n",
    "        return int.from_bytes(binary.read(4), byteorder='big')\n",
    "\n",
    "    @staticmethod\n",
    "    def read_long(binary: BytesIO):\n",
    "        return int.from_bytes(binary.read(8), byteorder='big')\n",
    "\n",
    "    @staticmethod\n",
    "    def read_message(binary: BytesIO, grpc_msg):\n",
    "        header = binary.read(1)\n",
    "        data = b'' if header == 0 else binary.read()\n",
    "        grpc_msg.ParseFromString(data)\n",
    "        return grpc_msg\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_records(data: bytes):\n",
    "        bio = BytesIO(data)\n",
    "        size = len(data)\n",
    "        records = []\n",
    "        while size > 0:\n",
    "            length = BinaryHelper.read_int(bio)\n",
    "            ts = BinaryHelper.read_long(bio)\n",
    "            body = BytesIO(bio.read(length))\n",
    "            entries = BinaryHelper.decode_entries(body)\n",
    "            records.append(TsRecord(ts, entries))\n",
    "            size = size - length - 4 - 8\n",
    "        return records\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_entries(binary: BytesIO):\n",
    "        minUid = BinaryHelper.read_long(binary)\n",
    "        count = BinaryHelper.read_int(binary)\n",
    "        entries = []\n",
    "        for i in range(count):\n",
    "            length = BinaryHelper.read_int(binary)\n",
    "            data = binary.read(length)\n",
    "            entry = Entry(minUid + i, data)\n",
    "            entries.append(entry)\n",
    "        return entries\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_request(data: bytes):\n",
    "        return BinaryHelper.read_message(BytesIO(data), hs.PredictRequest())\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_response(data: bytes):\n",
    "        bio = BytesIO(data)\n",
    "        offset = BinaryHelper.read_int(bio)\n",
    "        print(offset)\n",
    "        data = BytesIO(bio.read())\n",
    "\n",
    "        if offset == 2:\n",
    "            return BinaryHelper.read_message(bio, hs.monitoring.ExecutionError())\n",
    "\n",
    "        elif offset == 3:\n",
    "            return BinaryHelper.read_message(data, hs.PredictResponse())\n",
    "        raise UnicodeDecodeError\n",
    "\n",
    "\n",
    "class Entry:\n",
    "    def __init__(self, uid, data):\n",
    "        self.uid = uid\n",
    "        self.binary = data\n",
    "        self.__request = None\n",
    "        self.__response = None\n",
    "\n",
    "    @property\n",
    "    def request(self):\n",
    "        if not self.__request:\n",
    "            self._read_binary()\n",
    "        return self.__request\n",
    "\n",
    "    @property\n",
    "    def response(self):\n",
    "        if not self.__response:\n",
    "            self._read_binary()\n",
    "        return self.__response\n",
    "\n",
    "    def _read_binary(self):\n",
    "        bio = BytesIO(self.binary)\n",
    "\n",
    "        request_size = BinaryHelper.read_int(bio)\n",
    "        response_size = BinaryHelper.read_int(bio)\n",
    "        self.__request = BinaryHelper.decode_request(bio.read(request_size))\n",
    "        self.__response = BinaryHelper.decode_response(bio.read(response_size))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Entry(uid={self.uid})\"\n",
    "\n",
    "\n",
    "class TsRecord:\n",
    "    def __init__(self, ts, entries):\n",
    "        self.ts = ts\n",
    "        self.entries = entries\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Record(ts={self.ts}, entries={self.entries})\"\n",
    "\n",
    "\n",
    "def join_entries(records: [TsRecord]):\n",
    "    return list(chain(*[item.entries for item in records]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
